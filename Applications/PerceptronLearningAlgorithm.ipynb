{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ba310f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import SPAM_import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d3465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y :  (4601,)\n",
      "Shape of X :  (4601, 57)\n",
      "y to_numeric :  [0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('data/spamdata.csv', sep=' ') \n",
    "# df = df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "# X = df.drop('isSPAM', axis=1).values \n",
    "# y = df['isSPAM'].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "data = SPAM_import()\n",
    "X_train = data.train_x\n",
    "y_train = data.train_y\n",
    "\n",
    "X_test = data.val_x\n",
    "y_test = data.val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLearning:\n",
    "    def __init__(self, learning_rate = 1.0, max_iter = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.w = None\n",
    "        self.b = 0\n",
    "    \n",
    "    def _step_function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        # regularize y to {0, 1}\n",
    "        y = np.where(y <= 0, 0, 1)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            errors = 0\n",
    "            for i in range(n_samples):\n",
    "                condition = y[i] * (np.dot(self.w, X[i]) + self.b)\n",
    "                if condition <= 0:\n",
    "                    # update\n",
    "                    self.w += self.learning_rate * y[i] * X[i]\n",
    "                    self.b += self.learning_rate * y[i]\n",
    "                    errors += 1\n",
    "            # if no error in this iterate\n",
    "            if errors == 0:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        # linear_output = np.dot(X, self.w) + self.b\n",
    "        # return np.where(linear_output >= 0, 1, 0)\n",
    "        linear_output = np.dot(X, self.w) + self.b\n",
    "        return self._step_function(linear_output)\n",
    "\n",
    "    def evaluation(self, X, y_true):\n",
    "        y_true = np.where(np.array(y_true) <= 0, 0, 1) # important\n",
    "        \n",
    "        y_pred = self.predict(X)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, pos_label=1, average = 'macro')\n",
    "        rec = recall_score(y_true, y_pred, pos_label=1, average = 'macro')\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1, average = 'macro')\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d37c1445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.5683\n",
      "Precision: 0.7263\n",
      "Recall: 0.6545\n",
      "F1-Score: 0.5549\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.99      0.31      0.48       289\n",
      "    Spam (1)       0.46      0.99      0.63       172\n",
      "\n",
      "    accuracy                           0.57       461\n",
      "   macro avg       0.73      0.65      0.55       461\n",
      "weighted avg       0.79      0.57      0.54       461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PerceptronLearning(learning_rate = 0.001)\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "eval_metrics = model.evaluation(X_test, y_test)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for metric, score in eval_metrics.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f840da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class PerceptronLearningOptimize:\n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def _step_function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        # Ensure labels are 0 and 1\n",
    "        y = np.array(y)\n",
    "        y = np.where(y <= 0, 0, 1)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            errors = 0\n",
    "            for idx in range(n_samples):\n",
    "                linear_output = np.dot(self.w, X[idx]) + self.b\n",
    "                y_pred = self._step_function(linear_output)\n",
    "\n",
    "                update = self.learning_rate * (y[idx] - y_pred)\n",
    "                if update != 0:\n",
    "                    self.w += update * X[idx]\n",
    "                    self.b += update\n",
    "                    errors += 1\n",
    "            if errors == 0:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.w) + self.b\n",
    "        return self._step_function(linear_output)\n",
    "\n",
    "    def evaluation(self, X, y_true):\n",
    "        y_true = np.where(np.array(y_true) <= 0, 0, 1)\n",
    "        y_pred = self.predict(X)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "        return {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b658bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9067245119305857\n",
      "Accuracy: {'Accuracy': 0.5683297180043384, 'Precision': 0.726272534464475, 'Recall': 0.6545324696225959, 'F1-Score': 0.5549264752257169}\n",
      "Accuracy: {'Accuracy': 0.8763557483731019, 'Precision': 0.8654221476248097, 'Recall': 0.8766697513478716, 'F1-Score': 0.8699911437434753}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# create fake data\n",
    "# X, y = make_classification(n_samples=100, n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "# y = 2 * y - 1\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# percetron model in skleran\n",
    "clf = Perceptron(max_iter=1000, tol=1e-3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "\n",
    "# percetron model v1\n",
    "clf = PerceptronLearning()\n",
    "clf.train(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", clf.evaluation(X_test, y_test))\n",
    "\n",
    "# percetron model optimize\n",
    "clf = PerceptronLearningOptimize()\n",
    "clf.train(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", clf.evaluation(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colorado_data_scienst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
